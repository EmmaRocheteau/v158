---
title: How Transferable are Self-supervised Features in Medical Image Classification
  Tasks?
abstract: Transfer learning has become a standard practice to mitigate the lack of
  labeled data in medical classification tasks. Whereas finetuning a downstream task
  using supervised ImageNet pretrained features is straightforward and extensively
  investigated in many works, there is little study on the usefulness of self-supervised
  pretraining. This paper assesses the transferability of the most recent self-supervised
  ImageNet models, including SimCLR, SwAV, and DINO, on selected medical imaging classification
  tasks. The chosen tasks cover tumor detection in sentinel axillary lymph node images,
  diabetic retinopathy classification in fundus images, and multiple pathological
  condition classification in chest X-ray images. We demonstrate that self-supervised
  pretrained models yield richer embeddings than their supervised counterparts, benefiting
  downstream tasks for linear evaluation and finetuning. For example, at a critically
  small subset of the data with linear evaluation, we see an improvement up to 14.79%
  in Kappa score in the diabetic retinopathy classification task, 5.4% in AUC in the
  tumor classification task, 7.03% AUC in the pneumonia detection, and 9.4% in AUC
  in the detection of pathological conditions in chest X-ray. In addition, we introduce
  Dynamic Visual Meta-Embedding (DVME) as an end-to-end transfer learning approach
  that fuses pretrained embeddings from multiple models. We show that the collective
  representation obtained by DVME leads to a significant improvement in the performance
  of selected tasks compared to using a single pretrained model approach and can be
  generalized to any combination of pretrained models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: truong21a
month: 0
tex_title: How Transferable are Self-supervised Features in Medical Image Classification
  Tasks?
firstpage: 54
lastpage: 74
page: 54-74
order: 54
cycles: false
bibtex_author: Truong, Tuan and Mohammadi, Sadegh and Lenga, Matthias
author:
- given: Tuan
  family: Truong
- given: Sadegh
  family: Mohammadi
- given: Matthias
  family: Lenga
date: 2021-11-28
address:
container-title: Proceedings of Machine Learning for Health
volume: '158'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 11
  - 28
pdf: https://proceedings.mlr.press/v158/truong21a/truong21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
